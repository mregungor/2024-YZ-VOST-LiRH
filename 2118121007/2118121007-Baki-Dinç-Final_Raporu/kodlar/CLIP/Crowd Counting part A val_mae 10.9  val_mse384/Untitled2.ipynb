{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ec4a71-b994-4b31-ac7e-cb5c890de467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pykdtree in c:\\users\\bakid\\anaconda3\\lib\\site-packages (1.3.11)\n",
      "Requirement already satisfied: numpy in c:\\users\\bakid\\anaconda3\\lib\\site-packages (from pykdtree) (1.26.4)\n",
      "Requirement already satisfied: kdtree in c:\\users\\bakid\\anaconda3\\lib\\site-packages (0.16)\n"
     ]
    }
   ],
   "source": [
    "#Definition of library\n",
    "!pip install pykdtree\n",
    "!pip install kdtree\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import argparse\n",
    "from scipy.io import loadmat\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "from scipy.io import loadmat\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from pykdtree.kdtree import KDTree\n",
    "import glob\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import scipy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from utils_gen import gen_density_map_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e5ce96c-c1bd-4342-aa64-a2232a8b2d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_density_map(img, anno_points):\n",
    "   \n",
    "    density_map = np.zeros_like(img, dtype=np.float64)\n",
    "    h, w = density_map.shape\n",
    "    kernel_size = 15 # Gaussian kernel size\n",
    "    sigma = 4.0 # standard deviation\n",
    "\n",
    "    for point in anno_points:\n",
    "        # Center point coordinates of human head\n",
    "        x, y = min(w-1, abs(math.floor(point[0]))), min(h-1, abs(math.floor(point[1])))\n",
    "        # Upper left corner coordinates and lower right corner coordinates\n",
    "        x1, y1 = x-kernel_size // 2, y-kernel_size // 2\n",
    "        x2, y2 = x + kernel_size // 2 + 1, y + kernel_size // 2 + 1\n",
    "\n",
    "        out_of_bounds = False\n",
    "        dx1, dy1, dx2, dy2 = 0, 0, 0, 0 # Out of bounds offset\n",
    "        # The following four ifs are used to determine whether the x and y of the two top corners are out of bounds\n",
    "        if x1 <0:\n",
    "            dx1 = abs(x1)\n",
    "            x1 = 0\n",
    "            out_of_bounds = True\n",
    "        if y1 <0:\n",
    "            dy1 = abs(y1)\n",
    "            y1 = 0\n",
    "            out_of_bounds = True\n",
    "        if x2> w:\n",
    "            dx2 = x2-w\n",
    "            x2 = w\n",
    "            out_of_bounds = True\n",
    "        if y2> h:\n",
    "            dy2 = y2-h\n",
    "            y2 = h\n",
    "            out_of_bounds = True\n",
    "\n",
    "        if out_of_bounds:\n",
    "            # If it is out of bounds, adjust the size of the Gaussian kernel\n",
    "            kernel_h = kernel_size-dy1-dy2\n",
    "            kernel_w = kernel_size-dx1-dx2\n",
    "            # Generate a Gaussian kernel of size (kernel_h, kernel_w)\n",
    "            H = np.multiply(cv2.getGaussianKernel(kernel_h, sigma), (cv2.getGaussianKernel(kernel_w, sigma)).T)\n",
    "        else:\n",
    "            # Generate a Gaussian kernel of size (15, 15)\n",
    "            H = np.multiply(cv2.getGaussianKernel(kernel_size, sigma), (cv2.getGaussianKernel(kernel_size, sigma)).T)\n",
    "\n",
    "        density_map[y1:y2, x1:x2] += H\n",
    "    return density_map\n",
    "\n",
    "\n",
    "class DataLoader(object):\n",
    "    def __init__(self, data_path, gt_path, shuffle=False, gt_downsample=False):\n",
    "     \n",
    "        self.data_path = data_path\n",
    "        self.gt_path = gt_path\n",
    "        self.shuffle = shuffle\n",
    "        self.gt_downsample = gt_downsample\n",
    "        self.data_files = [filename for filename in os.listdir(data_path)]\n",
    "        self.num_samples = len(self.data_files)\n",
    "        self.blob_list = []\n",
    "\n",
    "        for fname in self.data_files:\n",
    "            img = cv2.imread(os.path.join(self.data_path, fname), 0)\n",
    "            img = img.astype(np.float32, copy=False)\n",
    "            ht = img.shape[0]\n",
    "            wd = img.shape[1]\n",
    "            ht_1 = int((ht / 4) * 4)\n",
    "            wd_1 = int((wd / 4) * 4)\n",
    "            img = cv2.resize(img, (wd_1, ht_1))\n",
    "            img = img.reshape((img.shape[0], img.shape[1], 1))\n",
    "            den = pd.read_csv(os.path.join(self.gt_path, os.path.splitext(fname)[0] +'.csv'),\n",
    "                              header=None).values\n",
    "            den = den.astype(np.float32, copy=False)\n",
    "            if self.gt_downsample:\n",
    "                wd_1 = int(wd_1 / 4)\n",
    "                ht_1 = int(ht_1 / 4)\n",
    "            den = cv2.resize(den, (wd_1, ht_1))\n",
    "            den = den * ((wd * ht) / (wd_1 * ht_1))\n",
    "            den = den.reshape((den.shape[0], den.shape[1], 1))\n",
    "\n",
    "            blob = dict()\n",
    "            blob['data'] = img\n",
    "            blob['gt'] = den\n",
    "            blob['fname'] = fname\n",
    "            self.blob_list.append(blob)\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.blob_list)\n",
    "\n",
    "    def flow(self, batch_size=32):\n",
    "        loop_count = self.num_samples // batch_size\n",
    "        while True:\n",
    "            np.random.shuffle(self.blob_list)\n",
    "            for i in range(loop_count):\n",
    "                blobs = self.blob_list[i*batch_size: (i+1)*batch_size]\n",
    "                X_batch = np.array([blob['data'] for blob in blobs])\n",
    "                Y_batch = np.array([blob['gt'] for blob in blobs])\n",
    "                yield X_batch, Y_batch\n",
    "\n",
    "    def get_all(self):\n",
    "        X = np.array([blob['data'] for blob in self.blob_list])\n",
    "        Y = np.array([blob['gt'] for blob in self.blob_list])\n",
    "        return X, Y\n",
    "\n",
    "    def __iter__(self):\n",
    "        for blob in self.blob_list:\n",
    "            yield blob\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return K.abs(K.sum(y_true) - K.sum(y_pred))\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return (K.sum(y_true) - K.sum(y_pred)) * (K.sum(y_true) - K.sum(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c327ab-87c2-4fb9-b1fc-1032837fff73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
