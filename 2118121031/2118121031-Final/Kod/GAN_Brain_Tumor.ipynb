{"cells":[{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Flatten, Conv2D, Reshape, Input, Conv2DTranspose, LeakyReLU, BatchNormalization, Dropout\n","from keras.optimizers import Adam\n","from tensorflow.keras.models import load_model\n","from tqdm import tqdm\n","import seaborn as sns\n","\n","\n","# Google Drive'a bağlan\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Görüntüleri yükleme fonksiyonu\n","def load_images(folder):\n","    imgs = []\n","    target = 1\n","    labels = []\n","    for i in os.listdir(folder):\n","        img_dir = os.path.join(folder,i)\n","        try:\n","            img = cv2.imread(img_dir)\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","            img = cv2.resize(img, (128,128))\n","            imgs.append(img)\n","            labels.append(target)\n","        except:\n","            continue\n","\n","    imgs = np.array(imgs)\n","    labels = np.array(labels)\n","\n","    return imgs, labels\n","\n","# Üretici Model\n","def build_generator():\n","    model = Sequential([\n","        Dense(32*32*256, input_dim=NOISE_DIM),\n","        LeakyReLU(alpha=0.2),\n","        Reshape((32,32,256)),\n","\n","        Conv2DTranspose(128, (4, 4), strides=2, padding='same'),\n","        LeakyReLU(alpha=0.2),\n","\n","        Conv2DTranspose(128, (4, 4), strides=2, padding='same'),\n","        LeakyReLU(alpha=0.2),\n","\n","        Conv2D(CHANNELS, (4, 4), padding='same', activation='tanh')\n","    ],\n","    name=\"generator\")\n","    model.summary()\n","    model.compile(loss=\"binary_crossentropy\", optimizer=OPTIMIZER)\n","    return model\n","\n","# Ayrıştırıcı Model\n","def build_discriminator():\n","    model = Sequential([\n","        Conv2D(64, (3, 3), padding='same', input_shape=(WIDTH, HEIGHT, CHANNELS)),\n","        LeakyReLU(alpha=0.2),\n","\n","        Conv2D(128, (3, 3), strides=2, padding='same'),\n","        LeakyReLU(alpha=0.2),\n","\n","        Conv2D(128, (3, 3), strides=2, padding='same'),\n","        LeakyReLU(alpha=0.2),\n","\n","        Conv2D(256, (3, 3), strides=2, padding='same'),\n","        LeakyReLU(alpha=0.2),\n","\n","        Flatten(),\n","        Dropout(0.4),\n","        Dense(1, activation=\"sigmoid\")\n","    ], name=\"discriminator\")\n","    model.summary()\n","    model.compile(loss=\"binary_crossentropy\", optimizer=OPTIMIZER)\n","    return model\n","\n","# GAN Model\n","def build_gan(generator, discriminator):\n","    discriminator.trainable = False\n","    gan_input = Input(shape=(NOISE_DIM,))\n","    fake_image = generator(gan_input)\n","    gan_output = discriminator(fake_image)\n","    gan = Model(gan_input, gan_output, name=\"gan_model\")\n","    gan.compile(loss=\"binary_crossentropy\", optimizer=OPTIMIZER)\n","    return gan\n","\n","# Fonksiyonunuz\n","def sample_images(generator, noise, subplots, figsize=(22, 8), save=False):\n","    generated_images = generator.predict(noise)\n","    plt.figure(figsize=figsize)\n","\n","    for i, image in enumerate(generated_images):\n","        plt.subplot(subplots[0], subplots[1], i+1)\n","        if CHANNELS == 1:\n","            image = image.reshape((WIDTH, HEIGHT))\n","            plt.imshow(image, cmap='gray')\n","        else:\n","            image = image.reshape((WIDTH, HEIGHT, CHANNELS))\n","            plt.imshow(image)\n","        if save:\n","            img_name = \"gen\" + str(i)\n","            plt.savefig(img_name)\n","        plt.subplots_adjust(wspace=None, hspace=None)\n","        plt.axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Parametreler\n","NOISE_DIM = 100\n","BATCH_SIZE = 4\n","STEPS_PER_EPOCH = 3750\n","EPOCHS = 10\n","SEED = 42\n","WIDTH, HEIGHT, CHANNELS = 128, 128, 1\n","OPTIMIZER = Adam(0.0002, 0.5)\n","MAIN_DIR = \"/content/drive/MyDrive/archive/MY_data/yes\"\n","\n","# Veri yükleme\n","data, labels = load_images(MAIN_DIR)\n","print(\"Data shape:\", data.shape)\n","print(\"Labels shape:\", labels.shape)\n","\n","# Rastgele örnekler seç\n","np.random.seed(SEED)\n","idxs = np.random.randint(0, len(data), 20)\n","X_train = data[idxs]\n","\n","# Verilerin normalizasyonu\n","data_normalized = (data.astype(np.float32) - 127.5) / 127.5\n","\n","# Resimleri yeniden şekillendirme\n","X_train = data_normalized.reshape(-1, WIDTH, HEIGHT, CHANNELS)\n","\n","# Görüntüleri göster\n","plt.figure(figsize=(20, 8))\n","for i in range(10):\n","    axs = plt.subplot(2, 5, i+1)\n","    plt.imshow(X_train[i], cmap=\"gray\")\n","    plt.axis('off')\n","    axs.set_xticklabels([])\n","    axs.set_yticklabels([])\n","    plt.subplots_adjust(wspace=None, hspace=None)\n","plt.tight_layout()\n","plt.show()\n","\n","# Giriş verisini yeniden şekillendirme\n","NOISE_DIM = 100\n","\n","# Model oluşturma\n","discriminator = build_discriminator()\n","generator = build_generator()\n","gan = build_gan(generator, discriminator)\n","\n","# Model özetlerini görüntüleme\n","print(\"Discriminator Summary:\")\n","discriminator.summary()\n","print(\"\\nGenerator Summary:\")\n","generator.summary()\n","\n","# Build optimizer for all trainable variables\n","optimizer = Adam(0.0002, 0.5)\n","optimizer.build(generator.trainable_variables + discriminator.trainable_variables)\n","\n","gan.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n","\n","print(\"\\nGAN Summary:\")\n","gan.summary()\n","\n","# Eğitim\n","real = np.ones((BATCH_SIZE, 1))\n","fake = np.zeros((BATCH_SIZE, 1))\n","\n","for epoch in range(EPOCHS):\n","    for _ in tqdm(range(STEPS_PER_EPOCH)):\n","        # Rastgele gerçek resim seçme\n","        idx = np.random.randint(0, X_train.shape[0], BATCH_SIZE)\n","        real_images = X_train[idx]\n","\n","        # Gürültüden sahte resimler üretme\n","        noise = np.random.normal(0, 1, (BATCH_SIZE, NOISE_DIM))\n","        fake_images = generator.predict(noise)\n","\n","        # Ayrıştırıcıyı eğitme\n","        d_loss_real = discriminator.train_on_batch(real_images, real)\n","        d_loss_fake = discriminator.train_on_batch(fake_images, fake)\n","        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","        # Üreticiyi eğitme\n","        noise = np.random.normal(0, 1, (BATCH_SIZE, NOISE_DIM))\n","        g_loss = gan.train_on_batch(noise, real)\n","\n","    print(f\"Epoch: {epoch+1}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}\")\n","\n","    # Her epoch sonunda örnek resimler üretme ve kaydetme\n","    noise = np.random.normal(0, 1, (10, NOISE_DIM))\n","    sample_images(generator, noise, subplots=(5, 5), figsize=(10, 10), save=True)\n","\n","\n","\n","    # Sonuç görüntüleri üretme\n","noise = np.random.normal(0, 1, size=(100, NOISE_DIM))\n","sample_images(generator, noise, subplots=(10, 10), figsize=(24, 20), save=True)\n","\n","generated_images = generator.predict(noise)\n","generated_images.shape\n","\n","fig, axs = plt.subplots(ncols=1, nrows=1, figsize=(18,10))\n","\n","sns.distplot(X_train, label='Real Images', hist=True, color='#fc0328', ax=axs)\n","sns.distplot(generated_images, label='Generated Images', hist=True, color='#0c06c7', ax=axs)\n","\n","axs.legend(loc='upper right', prop={'size': 12})\n","\n","plt.show()\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1f_hqVbosDbcxK-URIiflUqkDpnVto8ED"},"id":"t2yuFvBPEpXO","executionInfo":{"status":"ok","timestamp":1714860637734,"user_tz":-180,"elapsed":40704106,"user":{"displayName":"Emre Akkaya","userId":"05579618547399920925"}},"outputId":"7fcb5a11-01d4-43a5-fda4-b90fc62ea94c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO5wFonOIguWo9nDo4R3A6b"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}